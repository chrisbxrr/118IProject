from openai import OpenAI

import streamlit as st

client = OpenAI(api_key="API KEY HERE") 

# create a text wrapper function
def get_completion(prompt, model="gpt-3.5-turbo"):
  completion = client.chat.completions.create(
      model=model,
      messages=[
      {"role": "system", "content":"You are a recycling expert who knows where to dispose of different types of waste materials. Provide a list of appropriate disposal methods and areas that the prompt contains."},
      {"role": "user", "content": prompt},
      ]
  )
  return completion.choices[0].message.content

st.title("Recycling Expert Chatbot")
with st.form(key='chat'):
  user_input = st.text_input("Ask me a question about what garbage is blocking your path currently and I will list some appropriate to dispose of it.")
  submit_button = st.form_submit_button(label='Submit')

  if submit_button:
    response = get_completion(user_input)
    st.write(response)

## FUNCTION 2

def transcribe_audio(audio_file_path):
    audio_file = open(audio_file_path, "rb")
    transcription = client.audio.transcriptions.create(
        model="whisper-1", 
        file=audio_file
    )
    return transcription.text

def key_points_extraction(transcription):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        temperature=0,
        messages=[
            {
                "role": "system",
                "content": "You are a proficient AI with a specialty in distilling information into key points. Based on the following text, identify and list the main points that were discussed or brought up. These should be the most important ideas, findings, or topics that are crucial to the essence of the discussion. Your goal is to provide a list that someone could read to quickly understand what was talked about."
            },
            {
                "role": "user",
                "content": transcription
            }
        ]
    )
    return response.choices[0].message.content

def action_item_extraction(transcription):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        temperature=0,
        messages=[
            {
                "role": "system",
                "content": "You are an AI expert in analyzing text extracting action items. Please review the text and identify and extract actionable steps from audio reports to address urban blight and safety hazards by identifying issues, assigning tasks, and prioritizing resolutions. Please list these action items clearly and concisely."
            },
            {
                "role": "user",
                "content": transcription
            }
        ]
    )
    return response.choices[0].message.content

# FUNCTION 3: NOTIFICATIONS
def send_notification(obstacle_description):
    """
    Notifies users about detected objects, hazards, or obstacles 
    and provides suggestions for the best course of action.
    
    Parameters:
    - obstacle_description (str): Description of the detected obstacle or hazard.
    
    Returns:
    - str: A notification message with a suggested action.
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        temperature=0,
        messages=[
            {
                "role": "system",
                "content": "You are an AI assistant that helps users navigate obstacles safely. Based on the described hazard or obstacle, provide a clear alert and a recommended action to avoid or mitigate the issue."
            },
            {
                "role": "user",
                "content": obstacle_description
            }
        ]
    )
    
    notification_message = response.choices[0].message.content
    st.warning(f"⚠️ Alert: {notification_message}")
    return notification_message

# FUNCTION 4: Computer Vision

def encode_image(image_path):
  with open(image_path, "rb") as image_file:
    return base64.b64encode(image_file.read()).decode('utf-8')

uploaded_file = st.file_uploader("Choose a picture file", type=["png", "jpg", "jpeg"])

openai.api_key = os.environ["OPENAI_API_KEY"]
client = OpenAI()

image_path = "images/cloud.png"

def photo_rec(image_path):
    base64_image = encode_image(image_path)
    response = client.chat.completions.create(
    model="gpt-4-turbo",
    messages=[
        {
        "role": "user",
        "content": [
            {"type": "text", "text": "What’s in this image in terms of food?"},
            {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/png;base64,{base64_image}",
            },
            },
        ],
        }
    ],
    max_tokens=300,
    )
    return response.choices[0].message.content


if uploaded_file is not None:
    with open(os.path.join('images',uploaded_file.name), 'wb') as f:
        f.write(uploaded_file.getbuffer())
    st.success("Saved File:{} to images".format(uploaded_file.name))
    image_path = os.path.join('images',uploaded_file.name)
    st.image(image_path)
    content = photo_rec(image_path)
    st.write(content)
